{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a7e27a-9101-4956-b83c-0cb7e0b792e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 10 20:00:18 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:51:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              62W / 400W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e381e-c059-42c9-8388-eed5682e6f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd3ac55-f2b2-45ab-9b24-3fe91ec8896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: update in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (0.0.1)\n",
      "Requirement already satisfied: torch in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (2.2.0+cu121)\n",
      "Requirement already satisfied: torchvision in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (0.17.0+cu121)\n",
      "Requirement already satisfied: torchaudio in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (2.2.0+cu121)\n",
      "Requirement already satisfied: transformers in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (4.40.0.dev0)\n",
      "Requirement already satisfied: style==1.1.0 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from update) (1.1.0)\n",
      "Requirement already satisfied: filelock in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: numpy in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: requests in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/cosuji/anaconda3/envs/bnb2/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install update torch torchvision torchaudio transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fabc057-d998-4135-85cf-f6542e5df06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d88e680-8aa8-4e6f-a252-0edb97c08d3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7cb3488-411e-4fae-8e99-c44b6b1b437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify a particular gpu to use if you have multiple ones. Here zero meane your first GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0484b-2ec7-436f-8669-1fee16e5fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_lines(path: str) -> list:\n",
    "    \"\"\"\n",
    "    Read lines from a file.\n",
    "\n",
    "    Args:\n",
    "    path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing the lines of the file.\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        contents = file.read()\n",
    "        lines = [line.strip() for line in contents.split('\\n')]\n",
    "        if lines and lines[-1] == '':\n",
    "            return lines[:-1]\n",
    "        return lines\n",
    "\n",
    "\n",
    "def write_files(write_path: str, result: list, mode: str = 'w') -> None:\n",
    "    \"\"\"\n",
    "    Write contents to a file.\n",
    "\n",
    "    Args:\n",
    "    write_path (str): The path to write the file.\n",
    "    result (list): The content to write to the file.\n",
    "    mode (str, optional): The writing mode. Defaults to 'w'.\n",
    "    \"\"\"\n",
    "    with open(write_path, mode) as f:\n",
    "        f.write('\\n'.join(result))\n",
    "        \n",
    "def write_file(write_path: str, result: str, mode: str = 'a') -> None:\n",
    "    \"\"\"\n",
    "    Write contents to a file.\n",
    "\n",
    "    Args:\n",
    "    write_path (str): The path to write the file.\n",
    "    results (list): The list of samples to write to the file.\n",
    "    mode (str, optional): The writing mode. Defaults to 'a' (append).\n",
    "    \"\"\"\n",
    "    with open(write_path, mode) as f:\n",
    "        f.write(result + '\\n')\n",
    "\n",
    "def create_directory(directory_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a directory if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "    directory_path (str): The path of the directory to be created.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)      \n",
    "        \n",
    "def create_file(file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a file if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path of the file to be created.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        pass  # This line does nothing, it's just to create an empty file\n",
    "\n",
    "import shutil\n",
    "\n",
    "def delete_directory(directory_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Delete a directory and its contents.\n",
    "\n",
    "    Args:\n",
    "    directory_path (str): The path of the directory to be deleted.\n",
    "    \"\"\"\n",
    "    shutil.rmtree(directory_path)\n",
    "    \n",
    "    \n",
    "import csv\n",
    "\n",
    "def create_csv(csv_file):\n",
    "    \"\"\"\n",
    "    Create a CSV file with two columns: 'Source' and 'Translation' and write the header row.\n",
    "\n",
    "    Args:\n",
    "    csv_file (str): The path of the CSV file to create.\n",
    "    \"\"\"\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Source', 'Translation']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        \n",
    "def append_to_csv(source, translation, csv_file):\n",
    "    \"\"\"\n",
    "    Append a single sample to a CSV file with two columns: 'Source' and 'Translation'.\n",
    "\n",
    "    Args:\n",
    "    source (str): The source text.\n",
    "    translation (str): The translation text.\n",
    "    csv_file (str): The path of the CSV file to append.\n",
    "    \"\"\"\n",
    "    with open(csv_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([source, translation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f1b59-23b7-43f3-94ed-d6301a9bf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_examples = {\n",
    "    1: {\n",
    "        'Input': 'Alfredo Zitarrosa died in Montevideo, Uruguay which is led by Raúl Fernando Sendic Rodríguez and Tabaré Vázquez.',\n",
    "        'Arabic': \".توفي ألفريدو زيتاروزا في مونتيفيديو، أوروغواي التي يقودها راؤول فرناندو سينديتش رودريغيز وتاباري فاسكيز\",\n",
    "        'Korean': \"영국의 수도는 런던으로, 돌로 만든 데드맨스 플랙(Dead Man's Plack)을 찾을 수 있습니다. Plack은 East Anglia의 Ealdorman인 Æthelwald에게 헌정되었습니다. 영국에서는 콘월어가 사용되며 영국 교회라는 종교가 확립되어 있습니다. 그 나라에서 발견되는 인종 그룹 중 하나는 영국계 아랍인입니다.\",\n",
    "        'Swahili': \"Mji mkuu wa Uingereza ni London ambapo tunaweza kupata Plack ya Dead Man ambayo imetengenezwa kwa mawe. Plack imejitolea kwa Æthelwald, Ealdorman wa East Anglia. Lugha ya Cornish inazungumzwa nchini Uingereza na ina dini iliyoanzishwa inayoitwa Kanisa la Anglikana. Moja ya makabila yanayopatikana katika nchi hiyo ni Waarabu wa Uingereza.\"\n",
    "    },\n",
    "    2: {\n",
    "        'Input': 'Angola International Airport is located at Ícolo e Bengo in Luanda province, Angola. The Airport is situated 159 meters above sea level and serves the city of Luanda.',\n",
    "        'Arabic': \".يقع مطار أنغولا الدولي في ايكولو ايبينغو في مقاطعة لواندا، أنغولا. يقع المطار على ارتفاع 159 مترًا فوق مستوى سطح البحر ويخدم مدينة لواندا\",\n",
    "        'Korean': \"앙골라 국제공항은 앙골라 루안다 지방의 이콜로 에 벤고에 위치해 있습니다. 공항은 해발 159미터에 위치해 있으며 루안다 시에 서비스를 제공합니다.\",\n",
    "        'Swahili': \"Uwanja wa ndege wa Kimataifa wa Angola uko Ícolo e Bengo katika jimbo la Luanda, Angola. Uwanja wa ndege upo mita 159 juu ya usawa wa bahari na unahudumia jiji la Luanda.\" \n",
    "    },\n",
    "    3: {\n",
    "        'Input': 'Akeem Adams, who plays for the Trinidad and Tobago national under-20 football team previously played for United Petrotrin FC whose ground is at Palo Seco.',\n",
    "        'Arabic': \".أكيم آدامز، الذي يلعب لصالح منتخب ترينيداد وتوباغو لكرة القدم تحت 20 سنة، سبق له اللعب مع نادي يونايتد بيتروترين لكرة القدم الذي يقع ملعبه في بالو سيكو\",\n",
    "        'Korean': \"트리니다드토바고 20세 이하 축구 국가대표팀에서 뛰고 있는 아킴 아담스는 팔로세코를 연고지로 하는 유나이티드 페트로트린 FC에서 선수 생활을 했습니다.\",\n",
    "        'Swahili': \"Akeem Adams, anayechezea timu ya taifa ya vijana ya Trinidad na Tobago ya soka ya vijana chini ya umri wa miaka 20 hapo awali aliichezea United Petrotrin FC ambayo uwanja wake ni Palo Seco.\"\n",
    "    },\n",
    "    4: {\n",
    "        'Input': 'The United States fighter pilot William Anders was born in British Hong Kong on the 17th of October, 1933. In 1963, he was chosen by NASA and became a crew member on Apollo 8.',\n",
    "        'Arabic': \".8 ولد الطيار المقاتل الأمريكي ويليام أندرس في هونغ كونغ البريطانية في 17 أكتوبر 1933. وفي عام 1963، تم اختياره من قبل وكالة ناسا وأصبح أحد أفراد طاقم أبولو \",\n",
    "        'Korean': \"미국 전투기 조종사 윌리엄 앤더스는 1933년 10월 17일 영국령 홍콩에서 태어났어요. 1963년 NASA에 발탁되어 아폴로 8호의 승무원이 되었습니다.\",\n",
    "        'Swahili': \"Rubani wa kivita wa Marekani William Anders alizaliwa Uingereza Hong Kong tarehe 17 Oktoba, 1933. Mnamo 1963, alichaguliwa na NASA na kuwa mwanachama wa wafanyakazi kwenye Apollo 8.\" \n",
    "    },\n",
    "    5: {\n",
    "        'Input': \"The capital of England is London where we can find the Dead Man's Plack which is made of stone. The Plack is dedicated to Æthelwald, Ealdorman of East Anglia. Cornish language is spoken in England and it has an established religion called the Church of England. One of the ethnic groups found in that country is the British Arabs.\",\n",
    "        'Arabic': \".عاصمة إنجلترا هي لندن حيث يمكننا العثور على نصب ديدمان بلاك تذكاري المصنوع من الحجر. المقام مخصص  للملك إيثلووف، زعيم و قائد من شرق أنجليا. يتم التحدث باللغة الكورنية في إنجلترا ولها دين راسخ يسمى كنيسة إنجلترا. إحدى المجموعات العرقية الموجودة في ذلك البلد هي العرب البريطانيين\",\n",
    "        'Korean': \"영국의 수도 런던에는 돌로 만든 데드맨의 플랙이 있습니다. 이 플랙은 이스트 앵글리아의 에델발드에게 헌정되어 있어요. 영국에서는 콘월어를 사용하며 영국 국교회라는 종교가 확립되어 있습니다. 이 나라에서 발견되는 인종 그룹 중 하나는 영국 아랍인입니다.\",\n",
    "        'Swahili': \"Mji mkuu wa Uingereza ni London ambapo tunaweza kupata Plack ya Dead Man ambayo imetengenezwa kwa mawe. Plack imejitolea kwa Æthelwald, Ealdorman wa East Anglia. Lugha ya Cornish inazungumzwa nchini Uingereza na ina dini iliyoanzishwa inayoitwa Kanisa la Anglikana. Moja ya makabila yanayopatikana katika nchi hiyo ni Waarabu wa Uingereza.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def generate_examples(data_examples, output):\n",
    "    examples = ''\n",
    "    for idx in range(1, 6):\n",
    "        examples += f\"\\nEnglish Text: {data_examples[idx]['Input']} \\n\\n{output} Text: {data_examples[idx][output]} \\n\\n\"\n",
    "    return examples\n",
    "\n",
    "\n",
    "def create_instruction(lang, source):\n",
    "    global data_examples\n",
    "    if lang == 'ko':\n",
    "        tgt_lang = \"Korean\"\n",
    "    elif lang == 'sw':\n",
    "        tgt_lang = \"Swahili\"\n",
    "    elif lang == 'ar':\n",
    "        tgt_lang = \"Arabic\"\n",
    "    else:\n",
    "        raise ValueError(\"Please use a valid language unicode\")\n",
    "\n",
    "    instruction = f\"Translate the following English language text to {tgt_lang} language text. Provide only the translation. Follow the example below. \\n\\n######\\n\"\n",
    "    examples = generate_examples(data_examples, tgt_lang)\n",
    "    prompt = f'''{instruction} \\nExamples:\\n{examples}\\nEnglish Text: {source}\\n{tgt_lang} Text:\\n'''\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15301bd5-9a33-4405-aaf6-2a203d430175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5474f8-49b4-4a34-872f-c2f95d6f6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, files_path):\n",
    "        self.files_path = files_path\n",
    "        self.files = [file for file in os.listdir(files_path) if file.endswith('.txt')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        texts = read_file_lines(os.path.join(self.files_path, file_name))\n",
    "        return texts, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a2eef-1a58-41fc-b061-a7b0758c6f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089acf9-4690-4b26-ae8b-5dfab9aa04c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"CohereForAI/c4ai-command-r-plus-4bit\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc441e-0ed6-494b-8537-4196c6d72b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a6286-dacd-42c4-bf99-fd98eba0775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(system, prompt):\n",
    "    # Format message with the command-r-plus chat template\n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": prompt\n",
    "            }\n",
    "    ]\n",
    "    text = pipe(messages, max_new_tokens=512)[0]['generated_text'][-1]['content']\n",
    "    return text\n",
    "\n",
    "\n",
    "def generate_(system, prompt):\n",
    "    # Format message with the command-r-plus chat template\n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": prompt\n",
    "            }\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "    gen_tokens = model.generate(\n",
    "    input_ids, \n",
    "    max_new_tokens=100, \n",
    "    do_sample=True, \n",
    "    temperature=0.3,\n",
    "    )\n",
    "    gen_text = tokenizer.decode(gen_tokens[0])\n",
    "    text = gen_text.split('<|CHATBOT_TOKEN|>')[1].replace('<|END_OF_TURN_TOKEN|>', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739bd83-7fe6-4311-b8bf-17c230874776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe use batching to for speedup\n",
    "#https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f7e270-88c1-4d5f-adc3-359738b2e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spinning/cosuji/NLG_Exp/gem\n"
     ]
    }
   ],
   "source": [
    "# !pwd #/spinning/cosuji/NLG_Exp/gem\n",
    "\n",
    "# translate/0_shot$ ls\n",
    "# counterfactual_mistral_base.txt_ko  counterfactual_mistral_base.txt_sw  factual_mistral_base.txt_ar  factual_struct_gpt_base.txt_ko\n",
    "# (bnb2) cosuji@g107:~/spinning-storage/cosuji/NLG_Exp/gem/results/translate/0_shot$ ls ../5_shot\n",
    "# counterfactual_mistral_base.txt_ar  counterfactual_mistral_base.txt_sw      fictional_struct_mistral_base_new.txt_ar\n",
    "# counterfactual_mistral_base.txt_ko  factual_struct_mistral_base_new.txt_ko  fictional_struct_mistral_base_new.txt_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c235c7-b809-45d7-8f10-b9c440a29a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'results/cleaned/5_shot'\n",
    "dataset = TranslationDataset(datapath)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712dc4f5-9ea8-4c9f-be50-8f9d25aa80a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['factual_mistral_base.txt', 'fictional_struct_mistral_base_new.txt', 'counterfactual_mistral_base.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a849c-b580-4abf-8183-b14cb96fcf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system prompt\n",
    "system = \"\"\"You are an expert language translator able to communicate and traslate one langage to another.\\n\n",
    "You should only translate the given text and provide only the translation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69682c79-6896-41bc-900f-315d4b2f8de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0_shot English to Arabic runs\n",
    "arabic_5_shot_path = '5_shot/arabic'\n",
    "create_directory(arabic_5_shot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d17b3e-548b-4b30-b0b9-cf48f9ef6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for texts, file_name in tqdm(dataloader, desc=\"Processing files\"):\n",
    "    # if file_name[0] in exclude: continue\n",
    "        \n",
    "    #path to create new file\n",
    "    outfile = os.path.join(arabic_5_shot_path, file_name[0])\n",
    "    csv_file = outfile.replace('.txt', '.csv')\n",
    "    \n",
    "    #create the file\n",
    "    create_file(outfile)\n",
    "    create_csv(csv_file)\n",
    "    \n",
    "    for text in tqdm(texts, desc=\"Translating texts\"):\n",
    "        text = text[0]\n",
    "        \n",
    "        prompt = create_instruction('ar', text)\n",
    "        result = generate(system, prompt)\n",
    "        \n",
    "        if result.startswith('arabic:') or result.startswith('Arabic:') or result.startswith('Arabic Text:') or result.startswith('arabic text:'):\n",
    "            result = result.replace('arabic:', '').replace('Arabic:', '').replace('Arabic Text:', '').replace('arabic text:', '').strip()\n",
    "        write_file(outfile, result, mode = 'a')\n",
    "        append_to_csv(text, result, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a205f-c465-401d-b498-271814b07675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2249a-d6f4-4636-9d12-c0b0f1ee62e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949c3ce-62e4-4d5f-990c-7c56bd072422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19f31c-fefe-46d9-bdf8-b0826a43e752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053acd6f-556b-4906-b29d-2b7fbf6753ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fc028-54f6-495a-8a7f-5250d865e5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabf9f1-e1cd-4699-96fb-512f7d8698fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a05c2-84b7-41ab-b1ae-e0afa0975d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01af1e-24ef-4b87-86f4-a778483a4d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a8736-5865-47d4-a944-fe2bb88083b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3400f4-c166-4663-b038-4fcc3ec5b60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e80815-0de5-40dc-82b1-9212a46b9028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647323b6-d57e-481d-894b-869d9d45e4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
